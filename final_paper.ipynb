{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>candidate</th>\n",
       "      <th>party</th>\n",
       "      <th>candidatevotes</th>\n",
       "      <th>totalvotes</th>\n",
       "      <th>population_2022</th>\n",
       "      <th>district</th>\n",
       "      <th>N1</th>\n",
       "      <th>...</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>N11</th>\n",
       "      <th>N12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>AL GORE</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>5092</td>\n",
       "      <td>11925</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>MIDDLESEX</td>\n",
       "      <td>MATHEWS</td>\n",
       "      <td>NORTHAMPTON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>GEORGE W. BUSH</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>6352</td>\n",
       "      <td>11925</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>MIDDLESEX</td>\n",
       "      <td>MATHEWS</td>\n",
       "      <td>NORTHAMPTON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>RALPH NADER</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>220</td>\n",
       "      <td>11925</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>MIDDLESEX</td>\n",
       "      <td>MATHEWS</td>\n",
       "      <td>NORTHAMPTON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>261</td>\n",
       "      <td>11925</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>MIDDLESEX</td>\n",
       "      <td>MATHEWS</td>\n",
       "      <td>NORTHAMPTON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>JOHN KERRY</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>5518</td>\n",
       "      <td>13356</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>MIDDLESEX</td>\n",
       "      <td>MATHEWS</td>\n",
       "      <td>NORTHAMPTON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year county_name  county_fips       candidate       party  candidatevotes  \\\n",
       "0  2000    ACCOMACK        51001         AL GORE    DEMOCRAT            5092   \n",
       "1  2000    ACCOMACK        51001  GEORGE W. BUSH  REPUBLICAN            6352   \n",
       "2  2000    ACCOMACK        51001     RALPH NADER       GREEN             220   \n",
       "3  2000    ACCOMACK        51001           OTHER       OTHER             261   \n",
       "4  2004    ACCOMACK        51001      JOHN KERRY    DEMOCRAT            5518   \n",
       "\n",
       "   totalvotes  population_2022  district              N1  ...         N3  \\\n",
       "0       11925            33191         2  NORTHUMBERLAND  ...  MIDDLESEX   \n",
       "1       11925            33191         2  NORTHUMBERLAND  ...  MIDDLESEX   \n",
       "2       11925            33191         2  NORTHUMBERLAND  ...  MIDDLESEX   \n",
       "3       11925            33191         2  NORTHUMBERLAND  ...  MIDDLESEX   \n",
       "4       13356            33191         2  NORTHUMBERLAND  ...  MIDDLESEX   \n",
       "\n",
       "        N4           N5   N6   N7   N8   N9  N10  N11  N12  \n",
       "0  MATHEWS  NORTHAMPTON  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  MATHEWS  NORTHAMPTON  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  MATHEWS  NORTHAMPTON  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  MATHEWS  NORTHAMPTON  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  MATHEWS  NORTHAMPTON  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('merged_data.csv')\n",
    "nhgis = pd.read_csv('./data/df_melt.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>AV0AA</th>\n",
       "      <th>B78AA</th>\n",
       "      <th>AV1AA</th>\n",
       "      <th>AV1AB</th>\n",
       "      <th>AT5AA</th>\n",
       "      <th>AT5AB</th>\n",
       "      <th>AL8AA</th>\n",
       "      <th>AL8AB</th>\n",
       "      <th>...</th>\n",
       "      <th>A88AD</th>\n",
       "      <th>A88AE</th>\n",
       "      <th>AB2AA</th>\n",
       "      <th>BD5AA</th>\n",
       "      <th>AX6AA</th>\n",
       "      <th>CL6AA</th>\n",
       "      <th>AX7AA</th>\n",
       "      <th>AX7AB</th>\n",
       "      <th>BV8AA</th>\n",
       "      <th>BV8AB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>51001</td>\n",
       "      <td>38305.00</td>\n",
       "      <td>38305.00</td>\n",
       "      <td>18590.00</td>\n",
       "      <td>19715.00</td>\n",
       "      <td>36680.00</td>\n",
       "      <td>1625.00</td>\n",
       "      <td>22535.00</td>\n",
       "      <td>13983.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>51001</td>\n",
       "      <td>33454.00</td>\n",
       "      <td>33454.00</td>\n",
       "      <td>16230.00</td>\n",
       "      <td>17224.00</td>\n",
       "      <td>31192.00</td>\n",
       "      <td>2262.00</td>\n",
       "      <td>18212.00</td>\n",
       "      <td>12696.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2649.00</td>\n",
       "      <td>4604.00</td>\n",
       "      <td>50250.00</td>\n",
       "      <td>22909.00</td>\n",
       "      <td>33012.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>26334.00</td>\n",
       "      <td>1002.00</td>\n",
       "      <td>5147.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>51001</td>\n",
       "      <td>32673.00</td>\n",
       "      <td>32673.00</td>\n",
       "      <td>15934.00</td>\n",
       "      <td>16739.00</td>\n",
       "      <td>30148.00</td>\n",
       "      <td>2525.00</td>\n",
       "      <td>18418.00</td>\n",
       "      <td>11366.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.00</td>\n",
       "      <td>5072.00</td>\n",
       "      <td>57711.00</td>\n",
       "      <td>26018.00</td>\n",
       "      <td>32325.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>26184.00</td>\n",
       "      <td>677.00</td>\n",
       "      <td>6603.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>51003</td>\n",
       "      <td>79236.00</td>\n",
       "      <td>79236.00</td>\n",
       "      <td>38002.00</td>\n",
       "      <td>41234.00</td>\n",
       "      <td>73483.00</td>\n",
       "      <td>5753.00</td>\n",
       "      <td>39195.00</td>\n",
       "      <td>33535.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5153.00</td>\n",
       "      <td>13401.00</td>\n",
       "      <td>63407.00</td>\n",
       "      <td>28852.00</td>\n",
       "      <td>77661.00</td>\n",
       "      <td>5232.00</td>\n",
       "      <td>5232.00</td>\n",
       "      <td>72429.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>8756.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>51003</td>\n",
       "      <td>99484.00</td>\n",
       "      <td>99484.00</td>\n",
       "      <td>47564.00</td>\n",
       "      <td>51920.00</td>\n",
       "      <td>89589.00</td>\n",
       "      <td>9895.00</td>\n",
       "      <td>46267.00</td>\n",
       "      <td>41638.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3715.00</td>\n",
       "      <td>18225.00</td>\n",
       "      <td>89768.00</td>\n",
       "      <td>37837.00</td>\n",
       "      <td>93607.00</td>\n",
       "      <td>8321.00</td>\n",
       "      <td>8321.00</td>\n",
       "      <td>85286.00</td>\n",
       "      <td>643.00</td>\n",
       "      <td>13285.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR   FIPS    AV0AA    B78AA    AV1AA    AV1AB    AT5AA   AT5AB    AL8AA  \\\n",
       "0  2000  51001 38305.00 38305.00 18590.00 19715.00 36680.00 1625.00 22535.00   \n",
       "1   125  51001 33454.00 33454.00 16230.00 17224.00 31192.00 2262.00 18212.00   \n",
       "2   195  51001 32673.00 32673.00 15934.00 16739.00 30148.00 2525.00 18418.00   \n",
       "3  2000  51003 79236.00 79236.00 38002.00 41234.00 73483.00 5753.00 39195.00   \n",
       "4   125  51003 99484.00 99484.00 47564.00 51920.00 89589.00 9895.00 46267.00   \n",
       "\n",
       "     AL8AB  ...   A88AD    A88AE    AB2AA    BD5AA    AX6AA   CL6AA   AX7AA  \\\n",
       "0 13983.00  ... 3781.00  3195.00 34821.00 16309.00 37715.00 6788.00 6788.00   \n",
       "1 12696.00  ... 2649.00  4604.00 50250.00 22909.00 33012.00 6678.00 6678.00   \n",
       "2 11366.00  ... 2395.00  5072.00 57711.00 26018.00 32325.00 6141.00 6141.00   \n",
       "3 33535.00  ... 5153.00 13401.00 63407.00 28852.00 77661.00 5232.00 5232.00   \n",
       "4 41638.00  ... 3715.00 18225.00 89768.00 37837.00 93607.00 8321.00 8321.00   \n",
       "\n",
       "     AX7AB   BV8AA    BV8AB  \n",
       "0 30927.00  957.00  5291.00  \n",
       "1 26334.00 1002.00  5147.00  \n",
       "2 26184.00  677.00  6603.00  \n",
       "3 72429.00  430.00  8756.00  \n",
       "4 85286.00  643.00 13285.00  \n",
       "\n",
       "[5 rows x 162 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhgis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 162)\n"
     ]
    }
   ],
   "source": [
    "# in nhgis, rename all values with year as '125' to 2008'\n",
    "nhgis['YEAR'] = nhgis['YEAR'].replace(125, 2008)\n",
    "# in nhgis, rename all values with year as '195' to 2016'\n",
    "nhgis['YEAR'] = nhgis['YEAR'].replace(195, 2016)\n",
    "print(nhgis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(822, 162)\n"
     ]
    }
   ],
   "source": [
    "# for each row, if 'YEAR' is 2000, duplicate the row and change 'YEAR' to 2004. if 'YEAR' is 2008, duplicate the row and change 'YEAR' to 20012. if 'YEAR' is 2016, duplicate the row and change 'YEAR' to 2020.\n",
    "df_2004 = nhgis[nhgis['YEAR'] == 2000].copy()\n",
    "df_2004['YEAR'] = 2004\n",
    "\n",
    "df_2012 = nhgis[nhgis['YEAR'] == 2008].copy()\n",
    "df_2012['YEAR'] = 2012\n",
    "\n",
    "df_2020 = nhgis[nhgis['YEAR'] == 2016].copy()\n",
    "df_2020['YEAR'] = 2020\n",
    "\n",
    "# Use pd.concat to append the new DataFrames to the original DataFrame\n",
    "nhgis = pd.concat([nhgis, df_2004, df_2012, df_2020], ignore_index=True)\n",
    "del df_2004, df_2012, df_2020\n",
    "print(nhgis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>AV0AA</th>\n",
       "      <th>B78AA</th>\n",
       "      <th>AV1AA</th>\n",
       "      <th>AV1AB</th>\n",
       "      <th>AT5AA</th>\n",
       "      <th>AT5AB</th>\n",
       "      <th>AL8AA</th>\n",
       "      <th>AL8AB</th>\n",
       "      <th>...</th>\n",
       "      <th>A88AD</th>\n",
       "      <th>A88AE</th>\n",
       "      <th>AB2AA</th>\n",
       "      <th>BD5AA</th>\n",
       "      <th>AX6AA</th>\n",
       "      <th>CL6AA</th>\n",
       "      <th>AX7AA</th>\n",
       "      <th>AX7AB</th>\n",
       "      <th>BV8AA</th>\n",
       "      <th>BV8AB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>51001</td>\n",
       "      <td>38305.00</td>\n",
       "      <td>38305.00</td>\n",
       "      <td>18590.00</td>\n",
       "      <td>19715.00</td>\n",
       "      <td>36680.00</td>\n",
       "      <td>1625.00</td>\n",
       "      <td>22535.00</td>\n",
       "      <td>13983.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>51001</td>\n",
       "      <td>33454.00</td>\n",
       "      <td>33454.00</td>\n",
       "      <td>16230.00</td>\n",
       "      <td>17224.00</td>\n",
       "      <td>31192.00</td>\n",
       "      <td>2262.00</td>\n",
       "      <td>18212.00</td>\n",
       "      <td>12696.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2649.00</td>\n",
       "      <td>4604.00</td>\n",
       "      <td>50250.00</td>\n",
       "      <td>22909.00</td>\n",
       "      <td>33012.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>26334.00</td>\n",
       "      <td>1002.00</td>\n",
       "      <td>5147.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>51001</td>\n",
       "      <td>32673.00</td>\n",
       "      <td>32673.00</td>\n",
       "      <td>15934.00</td>\n",
       "      <td>16739.00</td>\n",
       "      <td>30148.00</td>\n",
       "      <td>2525.00</td>\n",
       "      <td>18418.00</td>\n",
       "      <td>11366.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.00</td>\n",
       "      <td>5072.00</td>\n",
       "      <td>57711.00</td>\n",
       "      <td>26018.00</td>\n",
       "      <td>32325.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>26184.00</td>\n",
       "      <td>677.00</td>\n",
       "      <td>6603.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>51003</td>\n",
       "      <td>79236.00</td>\n",
       "      <td>79236.00</td>\n",
       "      <td>38002.00</td>\n",
       "      <td>41234.00</td>\n",
       "      <td>73483.00</td>\n",
       "      <td>5753.00</td>\n",
       "      <td>39195.00</td>\n",
       "      <td>33535.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5153.00</td>\n",
       "      <td>13401.00</td>\n",
       "      <td>63407.00</td>\n",
       "      <td>28852.00</td>\n",
       "      <td>77661.00</td>\n",
       "      <td>5232.00</td>\n",
       "      <td>5232.00</td>\n",
       "      <td>72429.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>8756.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>51003</td>\n",
       "      <td>99484.00</td>\n",
       "      <td>99484.00</td>\n",
       "      <td>47564.00</td>\n",
       "      <td>51920.00</td>\n",
       "      <td>89589.00</td>\n",
       "      <td>9895.00</td>\n",
       "      <td>46267.00</td>\n",
       "      <td>41638.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3715.00</td>\n",
       "      <td>18225.00</td>\n",
       "      <td>89768.00</td>\n",
       "      <td>37837.00</td>\n",
       "      <td>93607.00</td>\n",
       "      <td>8321.00</td>\n",
       "      <td>8321.00</td>\n",
       "      <td>85286.00</td>\n",
       "      <td>643.00</td>\n",
       "      <td>13285.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>51003</td>\n",
       "      <td>107405.00</td>\n",
       "      <td>107405.00</td>\n",
       "      <td>51363.00</td>\n",
       "      <td>56042.00</td>\n",
       "      <td>96238.00</td>\n",
       "      <td>11167.00</td>\n",
       "      <td>49663.00</td>\n",
       "      <td>44728.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3419.00</td>\n",
       "      <td>20884.00</td>\n",
       "      <td>103077.00</td>\n",
       "      <td>44799.00</td>\n",
       "      <td>100293.00</td>\n",
       "      <td>9142.00</td>\n",
       "      <td>9142.00</td>\n",
       "      <td>91151.00</td>\n",
       "      <td>881.00</td>\n",
       "      <td>18026.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000</td>\n",
       "      <td>51510</td>\n",
       "      <td>128283.00</td>\n",
       "      <td>128283.00</td>\n",
       "      <td>61974.00</td>\n",
       "      <td>66309.00</td>\n",
       "      <td>95683.00</td>\n",
       "      <td>32600.00</td>\n",
       "      <td>27840.00</td>\n",
       "      <td>65288.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6275.00</td>\n",
       "      <td>17685.00</td>\n",
       "      <td>67023.00</td>\n",
       "      <td>37645.00</td>\n",
       "      <td>126409.00</td>\n",
       "      <td>11279.00</td>\n",
       "      <td>11279.00</td>\n",
       "      <td>115130.00</td>\n",
       "      <td>939.00</td>\n",
       "      <td>9547.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>51510</td>\n",
       "      <td>140337.00</td>\n",
       "      <td>140337.00</td>\n",
       "      <td>67565.00</td>\n",
       "      <td>72772.00</td>\n",
       "      <td>105123.00</td>\n",
       "      <td>35214.00</td>\n",
       "      <td>31614.00</td>\n",
       "      <td>70093.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4415.00</td>\n",
       "      <td>23275.00</td>\n",
       "      <td>105721.00</td>\n",
       "      <td>54767.00</td>\n",
       "      <td>138832.00</td>\n",
       "      <td>11102.00</td>\n",
       "      <td>11102.00</td>\n",
       "      <td>127730.00</td>\n",
       "      <td>948.00</td>\n",
       "      <td>11587.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>51510</td>\n",
       "      <td>157613.00</td>\n",
       "      <td>157613.00</td>\n",
       "      <td>75954.00</td>\n",
       "      <td>81659.00</td>\n",
       "      <td>114677.00</td>\n",
       "      <td>42936.00</td>\n",
       "      <td>33586.00</td>\n",
       "      <td>75911.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3947.00</td>\n",
       "      <td>27731.00</td>\n",
       "      <td>130395.00</td>\n",
       "      <td>62679.00</td>\n",
       "      <td>156261.00</td>\n",
       "      <td>16108.00</td>\n",
       "      <td>16108.00</td>\n",
       "      <td>140153.00</td>\n",
       "      <td>1182.00</td>\n",
       "      <td>16164.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000</td>\n",
       "      <td>51005</td>\n",
       "      <td>12926.00</td>\n",
       "      <td>12926.00</td>\n",
       "      <td>6450.00</td>\n",
       "      <td>6476.00</td>\n",
       "      <td>12814.00</td>\n",
       "      <td>112.00</td>\n",
       "      <td>10074.00</td>\n",
       "      <td>2690.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1265.00</td>\n",
       "      <td>1789.00</td>\n",
       "      <td>45843.00</td>\n",
       "      <td>19635.00</td>\n",
       "      <td>12682.00</td>\n",
       "      <td>905.00</td>\n",
       "      <td>905.00</td>\n",
       "      <td>11777.00</td>\n",
       "      <td>212.00</td>\n",
       "      <td>1758.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2008</td>\n",
       "      <td>51005</td>\n",
       "      <td>16297.00</td>\n",
       "      <td>16297.00</td>\n",
       "      <td>7956.00</td>\n",
       "      <td>8341.00</td>\n",
       "      <td>15985.00</td>\n",
       "      <td>312.00</td>\n",
       "      <td>12414.00</td>\n",
       "      <td>3516.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1242.00</td>\n",
       "      <td>2803.00</td>\n",
       "      <td>56250.00</td>\n",
       "      <td>23680.00</td>\n",
       "      <td>15980.00</td>\n",
       "      <td>1671.00</td>\n",
       "      <td>1671.00</td>\n",
       "      <td>14309.00</td>\n",
       "      <td>225.00</td>\n",
       "      <td>2974.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>51005</td>\n",
       "      <td>15157.00</td>\n",
       "      <td>15157.00</td>\n",
       "      <td>7367.00</td>\n",
       "      <td>7790.00</td>\n",
       "      <td>14967.00</td>\n",
       "      <td>190.00</td>\n",
       "      <td>11602.00</td>\n",
       "      <td>3326.00</td>\n",
       "      <td>...</td>\n",
       "      <td>903.00</td>\n",
       "      <td>2524.00</td>\n",
       "      <td>58933.00</td>\n",
       "      <td>27338.00</td>\n",
       "      <td>14830.00</td>\n",
       "      <td>2925.00</td>\n",
       "      <td>2925.00</td>\n",
       "      <td>11905.00</td>\n",
       "      <td>307.00</td>\n",
       "      <td>3119.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2000</td>\n",
       "      <td>51007</td>\n",
       "      <td>11400.00</td>\n",
       "      <td>11400.00</td>\n",
       "      <td>5622.00</td>\n",
       "      <td>5778.00</td>\n",
       "      <td>11320.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>9214.00</td>\n",
       "      <td>2067.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1081.00</td>\n",
       "      <td>1466.00</td>\n",
       "      <td>47157.00</td>\n",
       "      <td>18858.00</td>\n",
       "      <td>11267.00</td>\n",
       "      <td>948.00</td>\n",
       "      <td>948.00</td>\n",
       "      <td>10319.00</td>\n",
       "      <td>167.00</td>\n",
       "      <td>1256.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2008</td>\n",
       "      <td>51007</td>\n",
       "      <td>12674.00</td>\n",
       "      <td>12674.00</td>\n",
       "      <td>6272.00</td>\n",
       "      <td>6402.00</td>\n",
       "      <td>12407.00</td>\n",
       "      <td>267.00</td>\n",
       "      <td>8770.00</td>\n",
       "      <td>3561.00</td>\n",
       "      <td>...</td>\n",
       "      <td>982.00</td>\n",
       "      <td>2045.00</td>\n",
       "      <td>58065.00</td>\n",
       "      <td>24548.00</td>\n",
       "      <td>12579.00</td>\n",
       "      <td>1272.00</td>\n",
       "      <td>1272.00</td>\n",
       "      <td>11307.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>1907.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>51007</td>\n",
       "      <td>12953.00</td>\n",
       "      <td>12953.00</td>\n",
       "      <td>6580.00</td>\n",
       "      <td>6373.00</td>\n",
       "      <td>12804.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>10247.00</td>\n",
       "      <td>2485.00</td>\n",
       "      <td>...</td>\n",
       "      <td>752.00</td>\n",
       "      <td>2406.00</td>\n",
       "      <td>81848.00</td>\n",
       "      <td>31688.00</td>\n",
       "      <td>12861.00</td>\n",
       "      <td>1375.00</td>\n",
       "      <td>1375.00</td>\n",
       "      <td>11486.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>2110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2000</td>\n",
       "      <td>51009</td>\n",
       "      <td>31894.00</td>\n",
       "      <td>31894.00</td>\n",
       "      <td>15208.00</td>\n",
       "      <td>16686.00</td>\n",
       "      <td>31506.00</td>\n",
       "      <td>388.00</td>\n",
       "      <td>25479.00</td>\n",
       "      <td>5859.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3202.00</td>\n",
       "      <td>3496.00</td>\n",
       "      <td>42876.00</td>\n",
       "      <td>16952.00</td>\n",
       "      <td>30277.00</td>\n",
       "      <td>3238.00</td>\n",
       "      <td>3238.00</td>\n",
       "      <td>27039.00</td>\n",
       "      <td>494.00</td>\n",
       "      <td>3762.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2008</td>\n",
       "      <td>51009</td>\n",
       "      <td>32301.00</td>\n",
       "      <td>32301.00</td>\n",
       "      <td>15406.00</td>\n",
       "      <td>16895.00</td>\n",
       "      <td>31712.00</td>\n",
       "      <td>589.00</td>\n",
       "      <td>24339.00</td>\n",
       "      <td>7249.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2343.00</td>\n",
       "      <td>4859.00</td>\n",
       "      <td>56237.00</td>\n",
       "      <td>22169.00</td>\n",
       "      <td>31151.00</td>\n",
       "      <td>3637.00</td>\n",
       "      <td>3637.00</td>\n",
       "      <td>27514.00</td>\n",
       "      <td>529.00</td>\n",
       "      <td>4878.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016</td>\n",
       "      <td>51009</td>\n",
       "      <td>31775.00</td>\n",
       "      <td>31775.00</td>\n",
       "      <td>15290.00</td>\n",
       "      <td>16485.00</td>\n",
       "      <td>31205.00</td>\n",
       "      <td>570.00</td>\n",
       "      <td>24084.00</td>\n",
       "      <td>6817.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2002.00</td>\n",
       "      <td>5522.00</td>\n",
       "      <td>70552.00</td>\n",
       "      <td>26712.00</td>\n",
       "      <td>30994.00</td>\n",
       "      <td>4327.00</td>\n",
       "      <td>4327.00</td>\n",
       "      <td>26667.00</td>\n",
       "      <td>590.00</td>\n",
       "      <td>5855.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2000</td>\n",
       "      <td>51011</td>\n",
       "      <td>13705.00</td>\n",
       "      <td>13705.00</td>\n",
       "      <td>6671.00</td>\n",
       "      <td>7034.00</td>\n",
       "      <td>13517.00</td>\n",
       "      <td>188.00</td>\n",
       "      <td>10994.00</td>\n",
       "      <td>2480.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1443.00</td>\n",
       "      <td>1555.00</td>\n",
       "      <td>41563.00</td>\n",
       "      <td>18086.00</td>\n",
       "      <td>13578.00</td>\n",
       "      <td>1547.00</td>\n",
       "      <td>1547.00</td>\n",
       "      <td>12031.00</td>\n",
       "      <td>431.00</td>\n",
       "      <td>1576.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2008</td>\n",
       "      <td>51011</td>\n",
       "      <td>14952.00</td>\n",
       "      <td>14952.00</td>\n",
       "      <td>7374.00</td>\n",
       "      <td>7578.00</td>\n",
       "      <td>14840.00</td>\n",
       "      <td>112.00</td>\n",
       "      <td>11379.00</td>\n",
       "      <td>3401.00</td>\n",
       "      <td>...</td>\n",
       "      <td>874.00</td>\n",
       "      <td>2632.00</td>\n",
       "      <td>59186.00</td>\n",
       "      <td>23021.00</td>\n",
       "      <td>14768.00</td>\n",
       "      <td>2425.00</td>\n",
       "      <td>2425.00</td>\n",
       "      <td>12343.00</td>\n",
       "      <td>356.00</td>\n",
       "      <td>2210.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR   FIPS     AV0AA     B78AA    AV1AA    AV1AB     AT5AA    AT5AB  \\\n",
       "0   2000  51001  38305.00  38305.00 18590.00 19715.00  36680.00  1625.00   \n",
       "1   2008  51001  33454.00  33454.00 16230.00 17224.00  31192.00  2262.00   \n",
       "2   2016  51001  32673.00  32673.00 15934.00 16739.00  30148.00  2525.00   \n",
       "3   2000  51003  79236.00  79236.00 38002.00 41234.00  73483.00  5753.00   \n",
       "4   2008  51003  99484.00  99484.00 47564.00 51920.00  89589.00  9895.00   \n",
       "5   2016  51003 107405.00 107405.00 51363.00 56042.00  96238.00 11167.00   \n",
       "6   2000  51510 128283.00 128283.00 61974.00 66309.00  95683.00 32600.00   \n",
       "7   2008  51510 140337.00 140337.00 67565.00 72772.00 105123.00 35214.00   \n",
       "8   2016  51510 157613.00 157613.00 75954.00 81659.00 114677.00 42936.00   \n",
       "9   2000  51005  12926.00  12926.00  6450.00  6476.00  12814.00   112.00   \n",
       "10  2008  51005  16297.00  16297.00  7956.00  8341.00  15985.00   312.00   \n",
       "11  2016  51005  15157.00  15157.00  7367.00  7790.00  14967.00   190.00   \n",
       "12  2000  51007  11400.00  11400.00  5622.00  5778.00  11320.00    80.00   \n",
       "13  2008  51007  12674.00  12674.00  6272.00  6402.00  12407.00   267.00   \n",
       "14  2016  51007  12953.00  12953.00  6580.00  6373.00  12804.00   149.00   \n",
       "15  2000  51009  31894.00  31894.00 15208.00 16686.00  31506.00   388.00   \n",
       "16  2008  51009  32301.00  32301.00 15406.00 16895.00  31712.00   589.00   \n",
       "17  2016  51009  31775.00  31775.00 15290.00 16485.00  31205.00   570.00   \n",
       "18  2000  51011  13705.00  13705.00  6671.00  7034.00  13517.00   188.00   \n",
       "19  2008  51011  14952.00  14952.00  7374.00  7578.00  14840.00   112.00   \n",
       "\n",
       "      AL8AA    AL8AB  ...   A88AD    A88AE     AB2AA    BD5AA     AX6AA  \\\n",
       "0  22535.00 13983.00  ... 3781.00  3195.00  34821.00 16309.00  37715.00   \n",
       "1  18212.00 12696.00  ... 2649.00  4604.00  50250.00 22909.00  33012.00   \n",
       "2  18418.00 11366.00  ... 2395.00  5072.00  57711.00 26018.00  32325.00   \n",
       "3  39195.00 33535.00  ... 5153.00 13401.00  63407.00 28852.00  77661.00   \n",
       "4  46267.00 41638.00  ... 3715.00 18225.00  89768.00 37837.00  93607.00   \n",
       "5  49663.00 44728.00  ... 3419.00 20884.00 103077.00 44799.00 100293.00   \n",
       "6  27840.00 65288.00  ... 6275.00 17685.00  67023.00 37645.00 126409.00   \n",
       "7  31614.00 70093.00  ... 4415.00 23275.00 105721.00 54767.00 138832.00   \n",
       "8  33586.00 75911.00  ... 3947.00 27731.00 130395.00 62679.00 156261.00   \n",
       "9  10074.00  2690.00  ... 1265.00  1789.00  45843.00 19635.00  12682.00   \n",
       "10 12414.00  3516.00  ... 1242.00  2803.00  56250.00 23680.00  15980.00   \n",
       "11 11602.00  3326.00  ...  903.00  2524.00  58933.00 27338.00  14830.00   \n",
       "12  9214.00  2067.00  ... 1081.00  1466.00  47157.00 18858.00  11267.00   \n",
       "13  8770.00  3561.00  ...  982.00  2045.00  58065.00 24548.00  12579.00   \n",
       "14 10247.00  2485.00  ...  752.00  2406.00  81848.00 31688.00  12861.00   \n",
       "15 25479.00  5859.00  ... 3202.00  3496.00  42876.00 16952.00  30277.00   \n",
       "16 24339.00  7249.00  ... 2343.00  4859.00  56237.00 22169.00  31151.00   \n",
       "17 24084.00  6817.00  ... 2002.00  5522.00  70552.00 26712.00  30994.00   \n",
       "18 10994.00  2480.00  ... 1443.00  1555.00  41563.00 18086.00  13578.00   \n",
       "19 11379.00  3401.00  ...  874.00  2632.00  59186.00 23021.00  14768.00   \n",
       "\n",
       "      CL6AA    AX7AA     AX7AB   BV8AA    BV8AB  \n",
       "0   6788.00  6788.00  30927.00  957.00  5291.00  \n",
       "1   6678.00  6678.00  26334.00 1002.00  5147.00  \n",
       "2   6141.00  6141.00  26184.00  677.00  6603.00  \n",
       "3   5232.00  5232.00  72429.00  430.00  8756.00  \n",
       "4   8321.00  8321.00  85286.00  643.00 13285.00  \n",
       "5   9142.00  9142.00  91151.00  881.00 18026.00  \n",
       "6  11279.00 11279.00 115130.00  939.00  9547.00  \n",
       "7  11102.00 11102.00 127730.00  948.00 11587.00  \n",
       "8  16108.00 16108.00 140153.00 1182.00 16164.00  \n",
       "9    905.00   905.00  11777.00  212.00  1758.00  \n",
       "10  1671.00  1671.00  14309.00  225.00  2974.00  \n",
       "11  2925.00  2925.00  11905.00  307.00  3119.00  \n",
       "12   948.00   948.00  10319.00  167.00  1256.00  \n",
       "13  1272.00  1272.00  11307.00   87.00  1907.00  \n",
       "14  1375.00  1375.00  11486.00  297.00  2110.00  \n",
       "15  3238.00  3238.00  27039.00  494.00  3762.00  \n",
       "16  3637.00  3637.00  27514.00  529.00  4878.00  \n",
       "17  4327.00  4327.00  26667.00  590.00  5855.00  \n",
       "18  1547.00  1547.00  12031.00  431.00  1576.00  \n",
       "19  2425.00  2425.00  12343.00  356.00  2210.00  \n",
       "\n",
       "[20 rows x 162 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhgis.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2544, 181)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>candidate</th>\n",
       "      <th>party</th>\n",
       "      <th>candidatevotes</th>\n",
       "      <th>totalvotes</th>\n",
       "      <th>population_2022</th>\n",
       "      <th>district</th>\n",
       "      <th>N1</th>\n",
       "      <th>...</th>\n",
       "      <th>A88AD</th>\n",
       "      <th>A88AE</th>\n",
       "      <th>AB2AA</th>\n",
       "      <th>BD5AA</th>\n",
       "      <th>AX6AA</th>\n",
       "      <th>CL6AA</th>\n",
       "      <th>AX7AA</th>\n",
       "      <th>AX7AB</th>\n",
       "      <th>BV8AA</th>\n",
       "      <th>BV8AB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>AL GORE</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>5092</td>\n",
       "      <td>11925</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>GEORGE W. BUSH</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>6352</td>\n",
       "      <td>11925</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>RALPH NADER</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>220</td>\n",
       "      <td>11925</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>261</td>\n",
       "      <td>11925</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>JOHN KERRY</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>5518</td>\n",
       "      <td>13356</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>GEORGE W. BUSH</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>7726</td>\n",
       "      <td>13356</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>112</td>\n",
       "      <td>13356</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>BARACK OBAMA</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>7607</td>\n",
       "      <td>15623</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2649.00</td>\n",
       "      <td>4604.00</td>\n",
       "      <td>50250.00</td>\n",
       "      <td>22909.00</td>\n",
       "      <td>33012.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>26334.00</td>\n",
       "      <td>1002.00</td>\n",
       "      <td>5147.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>JOHN MCCAIN</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>7833</td>\n",
       "      <td>15623</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2649.00</td>\n",
       "      <td>4604.00</td>\n",
       "      <td>50250.00</td>\n",
       "      <td>22909.00</td>\n",
       "      <td>33012.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>26334.00</td>\n",
       "      <td>1002.00</td>\n",
       "      <td>5147.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>183</td>\n",
       "      <td>15623</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2649.00</td>\n",
       "      <td>4604.00</td>\n",
       "      <td>50250.00</td>\n",
       "      <td>22909.00</td>\n",
       "      <td>33012.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>26334.00</td>\n",
       "      <td>1002.00</td>\n",
       "      <td>5147.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>BARACK OBAMA</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>7655</td>\n",
       "      <td>16051</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2649.00</td>\n",
       "      <td>4604.00</td>\n",
       "      <td>50250.00</td>\n",
       "      <td>22909.00</td>\n",
       "      <td>33012.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>26334.00</td>\n",
       "      <td>1002.00</td>\n",
       "      <td>5147.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>MITT ROMNEY</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>8213</td>\n",
       "      <td>16051</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2649.00</td>\n",
       "      <td>4604.00</td>\n",
       "      <td>50250.00</td>\n",
       "      <td>22909.00</td>\n",
       "      <td>33012.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>26334.00</td>\n",
       "      <td>1002.00</td>\n",
       "      <td>5147.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>183</td>\n",
       "      <td>16051</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2649.00</td>\n",
       "      <td>4604.00</td>\n",
       "      <td>50250.00</td>\n",
       "      <td>22909.00</td>\n",
       "      <td>33012.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>6678.00</td>\n",
       "      <td>26334.00</td>\n",
       "      <td>1002.00</td>\n",
       "      <td>5147.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>HILLARY CLINTON</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>6740</td>\n",
       "      <td>15818</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.00</td>\n",
       "      <td>5072.00</td>\n",
       "      <td>57711.00</td>\n",
       "      <td>26018.00</td>\n",
       "      <td>32325.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>26184.00</td>\n",
       "      <td>677.00</td>\n",
       "      <td>6603.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>DONALD TRUMP</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>8583</td>\n",
       "      <td>15818</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.00</td>\n",
       "      <td>5072.00</td>\n",
       "      <td>57711.00</td>\n",
       "      <td>26018.00</td>\n",
       "      <td>32325.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>26184.00</td>\n",
       "      <td>677.00</td>\n",
       "      <td>6603.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>495</td>\n",
       "      <td>15818</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.00</td>\n",
       "      <td>5072.00</td>\n",
       "      <td>57711.00</td>\n",
       "      <td>26018.00</td>\n",
       "      <td>32325.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>26184.00</td>\n",
       "      <td>677.00</td>\n",
       "      <td>6603.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>DONALD TRUMP</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>9172</td>\n",
       "      <td>16962</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.00</td>\n",
       "      <td>5072.00</td>\n",
       "      <td>57711.00</td>\n",
       "      <td>26018.00</td>\n",
       "      <td>32325.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>26184.00</td>\n",
       "      <td>677.00</td>\n",
       "      <td>6603.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>JO JORGENSEN</td>\n",
       "      <td>LIBERTARIAN</td>\n",
       "      <td>188</td>\n",
       "      <td>16962</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.00</td>\n",
       "      <td>5072.00</td>\n",
       "      <td>57711.00</td>\n",
       "      <td>26018.00</td>\n",
       "      <td>32325.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>26184.00</td>\n",
       "      <td>677.00</td>\n",
       "      <td>6603.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>JOSEPH R BIDEN JR</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>7578</td>\n",
       "      <td>16962</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.00</td>\n",
       "      <td>5072.00</td>\n",
       "      <td>57711.00</td>\n",
       "      <td>26018.00</td>\n",
       "      <td>32325.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>26184.00</td>\n",
       "      <td>677.00</td>\n",
       "      <td>6603.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020</td>\n",
       "      <td>ACCOMACK</td>\n",
       "      <td>51001</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>24</td>\n",
       "      <td>16962</td>\n",
       "      <td>33191</td>\n",
       "      <td>2</td>\n",
       "      <td>NORTHUMBERLAND</td>\n",
       "      <td>...</td>\n",
       "      <td>2395.00</td>\n",
       "      <td>5072.00</td>\n",
       "      <td>57711.00</td>\n",
       "      <td>26018.00</td>\n",
       "      <td>32325.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>6141.00</td>\n",
       "      <td>26184.00</td>\n",
       "      <td>677.00</td>\n",
       "      <td>6603.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year county_name  county_fips          candidate        party  \\\n",
       "0   2000    ACCOMACK        51001            AL GORE     DEMOCRAT   \n",
       "1   2000    ACCOMACK        51001     GEORGE W. BUSH   REPUBLICAN   \n",
       "2   2000    ACCOMACK        51001        RALPH NADER        GREEN   \n",
       "3   2000    ACCOMACK        51001              OTHER        OTHER   \n",
       "4   2004    ACCOMACK        51001         JOHN KERRY     DEMOCRAT   \n",
       "5   2004    ACCOMACK        51001     GEORGE W. BUSH   REPUBLICAN   \n",
       "6   2004    ACCOMACK        51001              OTHER        OTHER   \n",
       "7   2008    ACCOMACK        51001       BARACK OBAMA     DEMOCRAT   \n",
       "8   2008    ACCOMACK        51001        JOHN MCCAIN   REPUBLICAN   \n",
       "9   2008    ACCOMACK        51001              OTHER        OTHER   \n",
       "10  2012    ACCOMACK        51001       BARACK OBAMA     DEMOCRAT   \n",
       "11  2012    ACCOMACK        51001        MITT ROMNEY   REPUBLICAN   \n",
       "12  2012    ACCOMACK        51001              OTHER        OTHER   \n",
       "13  2016    ACCOMACK        51001    HILLARY CLINTON     DEMOCRAT   \n",
       "14  2016    ACCOMACK        51001       DONALD TRUMP   REPUBLICAN   \n",
       "15  2016    ACCOMACK        51001              OTHER        OTHER   \n",
       "16  2020    ACCOMACK        51001       DONALD TRUMP   REPUBLICAN   \n",
       "17  2020    ACCOMACK        51001       JO JORGENSEN  LIBERTARIAN   \n",
       "18  2020    ACCOMACK        51001  JOSEPH R BIDEN JR     DEMOCRAT   \n",
       "19  2020    ACCOMACK        51001              OTHER        OTHER   \n",
       "\n",
       "    candidatevotes  totalvotes  population_2022  district              N1  \\\n",
       "0             5092       11925            33191         2  NORTHUMBERLAND   \n",
       "1             6352       11925            33191         2  NORTHUMBERLAND   \n",
       "2              220       11925            33191         2  NORTHUMBERLAND   \n",
       "3              261       11925            33191         2  NORTHUMBERLAND   \n",
       "4             5518       13356            33191         2  NORTHUMBERLAND   \n",
       "5             7726       13356            33191         2  NORTHUMBERLAND   \n",
       "6              112       13356            33191         2  NORTHUMBERLAND   \n",
       "7             7607       15623            33191         2  NORTHUMBERLAND   \n",
       "8             7833       15623            33191         2  NORTHUMBERLAND   \n",
       "9              183       15623            33191         2  NORTHUMBERLAND   \n",
       "10            7655       16051            33191         2  NORTHUMBERLAND   \n",
       "11            8213       16051            33191         2  NORTHUMBERLAND   \n",
       "12             183       16051            33191         2  NORTHUMBERLAND   \n",
       "13            6740       15818            33191         2  NORTHUMBERLAND   \n",
       "14            8583       15818            33191         2  NORTHUMBERLAND   \n",
       "15             495       15818            33191         2  NORTHUMBERLAND   \n",
       "16            9172       16962            33191         2  NORTHUMBERLAND   \n",
       "17             188       16962            33191         2  NORTHUMBERLAND   \n",
       "18            7578       16962            33191         2  NORTHUMBERLAND   \n",
       "19              24       16962            33191         2  NORTHUMBERLAND   \n",
       "\n",
       "    ...   A88AD   A88AE    AB2AA    BD5AA    AX6AA   CL6AA   AX7AA    AX7AB  \\\n",
       "0   ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00 6788.00 30927.00   \n",
       "1   ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00 6788.00 30927.00   \n",
       "2   ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00 6788.00 30927.00   \n",
       "3   ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00 6788.00 30927.00   \n",
       "4   ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00 6788.00 30927.00   \n",
       "5   ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00 6788.00 30927.00   \n",
       "6   ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00 6788.00 30927.00   \n",
       "7   ... 2649.00 4604.00 50250.00 22909.00 33012.00 6678.00 6678.00 26334.00   \n",
       "8   ... 2649.00 4604.00 50250.00 22909.00 33012.00 6678.00 6678.00 26334.00   \n",
       "9   ... 2649.00 4604.00 50250.00 22909.00 33012.00 6678.00 6678.00 26334.00   \n",
       "10  ... 2649.00 4604.00 50250.00 22909.00 33012.00 6678.00 6678.00 26334.00   \n",
       "11  ... 2649.00 4604.00 50250.00 22909.00 33012.00 6678.00 6678.00 26334.00   \n",
       "12  ... 2649.00 4604.00 50250.00 22909.00 33012.00 6678.00 6678.00 26334.00   \n",
       "13  ... 2395.00 5072.00 57711.00 26018.00 32325.00 6141.00 6141.00 26184.00   \n",
       "14  ... 2395.00 5072.00 57711.00 26018.00 32325.00 6141.00 6141.00 26184.00   \n",
       "15  ... 2395.00 5072.00 57711.00 26018.00 32325.00 6141.00 6141.00 26184.00   \n",
       "16  ... 2395.00 5072.00 57711.00 26018.00 32325.00 6141.00 6141.00 26184.00   \n",
       "17  ... 2395.00 5072.00 57711.00 26018.00 32325.00 6141.00 6141.00 26184.00   \n",
       "18  ... 2395.00 5072.00 57711.00 26018.00 32325.00 6141.00 6141.00 26184.00   \n",
       "19  ... 2395.00 5072.00 57711.00 26018.00 32325.00 6141.00 6141.00 26184.00   \n",
       "\n",
       "     BV8AA   BV8AB  \n",
       "0   957.00 5291.00  \n",
       "1   957.00 5291.00  \n",
       "2   957.00 5291.00  \n",
       "3   957.00 5291.00  \n",
       "4   957.00 5291.00  \n",
       "5   957.00 5291.00  \n",
       "6   957.00 5291.00  \n",
       "7  1002.00 5147.00  \n",
       "8  1002.00 5147.00  \n",
       "9  1002.00 5147.00  \n",
       "10 1002.00 5147.00  \n",
       "11 1002.00 5147.00  \n",
       "12 1002.00 5147.00  \n",
       "13  677.00 6603.00  \n",
       "14  677.00 6603.00  \n",
       "15  677.00 6603.00  \n",
       "16  677.00 6603.00  \n",
       "17  677.00 6603.00  \n",
       "18  677.00 6603.00  \n",
       "19  677.00 6603.00  \n",
       "\n",
       "[20 rows x 181 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename 'YEAR' column to 'year' in nhgis and 'FIPS' column to 'county_fips' in nhgis\n",
    "nhgis = nhgis.rename(columns={'YEAR': 'year', 'FIPS': 'county_fips'})\n",
    "\n",
    "# go through rows of df and join by 'year' and 'county_fips' with nhgis.\n",
    "df = df.merge(nhgis, on=['year', 'county_fips'], how='left')\n",
    "print(df.shape)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AV0AA</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33454.00</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33454.00</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33454.00</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33454.00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33454.00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33454.00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32673.00</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32673.00</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32673.00</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32673.00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32673.00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32673.00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32673.00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AV0AA  year\n",
       "0  38305.00  2000\n",
       "1  38305.00  2000\n",
       "2  38305.00  2000\n",
       "3  38305.00  2000\n",
       "4  38305.00  2004\n",
       "5  38305.00  2004\n",
       "6  38305.00  2004\n",
       "7  33454.00  2008\n",
       "8  33454.00  2008\n",
       "9  33454.00  2008\n",
       "10 33454.00  2012\n",
       "11 33454.00  2012\n",
       "12 33454.00  2012\n",
       "13 32673.00  2016\n",
       "14 32673.00  2016\n",
       "15 32673.00  2016\n",
       "16 32673.00  2020\n",
       "17 32673.00  2020\n",
       "18 32673.00  2020\n",
       "19 32673.00  2020"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop column 'population_2022' in df\n",
    "df = df.drop(columns=['population_2022'])\n",
    "df.loc[: ,['AV0AA', 'year']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('properly_merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 180)\n",
      "(528, 180)\n"
     ]
    }
   ],
   "source": [
    "# split df into testing and training, where testing is all rows with year between 2000 and 2016 (inclusive), and training is all rows with year as 2020\n",
    "train_data = df[(df['year'] >= 2000) & (df['year'] <= 2016)]\n",
    "test_data = df[df['year'] == 2020]\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AV0AA</th>\n",
       "      <th>B78AA</th>\n",
       "      <th>AV1AA</th>\n",
       "      <th>AV1AB</th>\n",
       "      <th>AT5AA</th>\n",
       "      <th>AT5AB</th>\n",
       "      <th>AL8AA</th>\n",
       "      <th>AL8AB</th>\n",
       "      <th>AL8AC</th>\n",
       "      <th>AL8AD</th>\n",
       "      <th>...</th>\n",
       "      <th>A88AD</th>\n",
       "      <th>A88AE</th>\n",
       "      <th>AB2AA</th>\n",
       "      <th>BD5AA</th>\n",
       "      <th>AX6AA</th>\n",
       "      <th>CL6AA</th>\n",
       "      <th>AX7AA</th>\n",
       "      <th>AX7AB</th>\n",
       "      <th>BV8AA</th>\n",
       "      <th>BV8AB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>38305.00</td>\n",
       "      <td>18590.00</td>\n",
       "      <td>19715.00</td>\n",
       "      <td>36680.00</td>\n",
       "      <td>1625.00</td>\n",
       "      <td>22535.00</td>\n",
       "      <td>13983.00</td>\n",
       "      <td>4495.00</td>\n",
       "      <td>963.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>38305.00</td>\n",
       "      <td>18590.00</td>\n",
       "      <td>19715.00</td>\n",
       "      <td>36680.00</td>\n",
       "      <td>1625.00</td>\n",
       "      <td>22535.00</td>\n",
       "      <td>13983.00</td>\n",
       "      <td>4495.00</td>\n",
       "      <td>963.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>38305.00</td>\n",
       "      <td>18590.00</td>\n",
       "      <td>19715.00</td>\n",
       "      <td>36680.00</td>\n",
       "      <td>1625.00</td>\n",
       "      <td>22535.00</td>\n",
       "      <td>13983.00</td>\n",
       "      <td>4495.00</td>\n",
       "      <td>963.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>38305.00</td>\n",
       "      <td>18590.00</td>\n",
       "      <td>19715.00</td>\n",
       "      <td>36680.00</td>\n",
       "      <td>1625.00</td>\n",
       "      <td>22535.00</td>\n",
       "      <td>13983.00</td>\n",
       "      <td>4495.00</td>\n",
       "      <td>963.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38305.00</td>\n",
       "      <td>38305.00</td>\n",
       "      <td>18590.00</td>\n",
       "      <td>19715.00</td>\n",
       "      <td>36680.00</td>\n",
       "      <td>1625.00</td>\n",
       "      <td>22535.00</td>\n",
       "      <td>13983.00</td>\n",
       "      <td>4495.00</td>\n",
       "      <td>963.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>34821.00</td>\n",
       "      <td>16309.00</td>\n",
       "      <td>37715.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>6788.00</td>\n",
       "      <td>30927.00</td>\n",
       "      <td>957.00</td>\n",
       "      <td>5291.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AV0AA    B78AA    AV1AA    AV1AB    AT5AA   AT5AB    AL8AA    AL8AB  \\\n",
       "0 38305.00 38305.00 18590.00 19715.00 36680.00 1625.00 22535.00 13983.00   \n",
       "1 38305.00 38305.00 18590.00 19715.00 36680.00 1625.00 22535.00 13983.00   \n",
       "2 38305.00 38305.00 18590.00 19715.00 36680.00 1625.00 22535.00 13983.00   \n",
       "3 38305.00 38305.00 18590.00 19715.00 36680.00 1625.00 22535.00 13983.00   \n",
       "4 38305.00 38305.00 18590.00 19715.00 36680.00 1625.00 22535.00 13983.00   \n",
       "\n",
       "    AL8AC  AL8AD  ...   A88AD   A88AE    AB2AA    BD5AA    AX6AA   CL6AA  \\\n",
       "0 4495.00 963.00  ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00   \n",
       "1 4495.00 963.00  ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00   \n",
       "2 4495.00 963.00  ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00   \n",
       "3 4495.00 963.00  ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00   \n",
       "4 4495.00 963.00  ... 3781.00 3195.00 34821.00 16309.00 37715.00 6788.00   \n",
       "\n",
       "    AX7AA    AX7AB  BV8AA   BV8AB  \n",
       "0 6788.00 30927.00 957.00 5291.00  \n",
       "1 6788.00 30927.00 957.00 5291.00  \n",
       "2 6788.00 30927.00 957.00 5291.00  \n",
       "3 6788.00 30927.00 957.00 5291.00  \n",
       "4 6788.00 30927.00 957.00 5291.00  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all relevant features\n",
    "columns_for_pca = [col for col in df.columns if col not in ['year', 'county_fips', 'candidatevotes','totalvotes', 'county_name', 'party', 'candidate','district', 'N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10', 'N11', 'N12', \n",
    "                                                            'AL8AH', 'AK7AF', 'AB9AY', 'AJ6AA', 'AJ6AB', 'AJ6AC',\t'AJ6AD',\t'AJ6AE',\t'AJ6AF',\t'AJ6AG',\t'AJ6AH',\t'AJ6AI',\t'AJ6AJ',\t'AJ6AK',\t\n",
    "                                                            'AJ6AL',\t'AJ6AM',\t'AJ6AN',\t'AJ6AO',\t'AJ6AP',\t'AJ6AQ',\t'AJ6AR',\t'AJ6AS',\t'AJ6AT',\t'AJ6AU',\t'AJ6AV',\t'AJ6AW',\t'AJ6AX',\t'AJ6AY',\t\n",
    "                                                            'AJ6AZ',\t'AJ6BA',\t'AJ6BB',\t'AJ6BC',\t'AJ6BD'\n",
    "]]\n",
    "\n",
    "X = df[columns_for_pca]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "\n",
      "Principal Component 1:\n",
      "BS4AA: 0.1011\n",
      "B84AA: 0.1011\n",
      "BS4AG: 0.1009\n",
      "\n",
      "Principal Component 2:\n",
      "C54AD: 0.1823\n",
      "AB2AA: 0.1792\n",
      "BD5AA: 0.1779\n",
      "\n",
      "Principal Component 3:\n",
      "C54AD: 0.3191\n",
      "C54AB: 0.2808\n",
      "C54AG: 0.2562\n",
      "\n",
      "Principal Component 4:\n",
      "B69AA: 0.2681\n",
      "C54AE: 0.2548\n",
      "AK7AC: 0.2254\n",
      "\n",
      "Principal Component 5:\n",
      "BV8AA: 0.1809\n",
      "AB9AO: 0.1568\n",
      "A67AL: 0.1548\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create a PCA object and fit the scaled data\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Get the explained variance ratio for each principal component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "tot_variance = 0\n",
    "num_components = 0\n",
    "\n",
    "for ratio in explained_variance_ratio:\n",
    "    if tot_variance >= 0.90:\n",
    "        break\n",
    "    tot_variance += ratio\n",
    "    num_components +=1\n",
    "\n",
    "print(num_components)\n",
    "\n",
    "# Create a new PCA object 5 components\n",
    "n_components = 5  \n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "loadings = pca.components_\n",
    "\n",
    "column_names = X.columns\n",
    "\n",
    "# Top three contributing features for each principal component\n",
    "for i in range(n_components):\n",
    "    print(f\"\\nPrincipal Component {i+1}:\")\n",
    "    top_indices = loadings[i].argsort()[::-1][:3] \n",
    "    for index in top_indices:\n",
    "        print(f\"{column_names[index]}: {loadings[i][index]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both education and income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 143594647.7163835\n",
      "Root Mean Squared Error: 11983.098418872452\n",
      "Mean Absolute Error: 4787.315397727273\n",
      "Mean Absolute Percentage Error: 1332.42%\n",
      "R-squared: 0.5451191430748419\n"
     ]
    }
   ],
   "source": [
    "vars = ['year', 'county_name', 'party', 'totalvotes', \"AV0AA\", \"B69AA\", \"B69AB\", \"B69AC\", \"A88AA\",\"A88AB\",\"A88AC\",\"A88AD\",\"A88AE\"]\n",
    "\n",
    "X_train = train_data.loc[:, vars]\n",
    "Y_train = train_data.loc[:, 'candidatevotes']\n",
    "X_test = test_data.loc[:, vars]\n",
    "Y_test = test_data.loc[:, 'candidatevotes']\n",
    "\n",
    "# Encode categorical data\n",
    "X_train = pd.get_dummies(X_train, columns=['county_name', 'party'])\n",
    "X_test = pd.get_dummies(X_test, columns=['county_name', 'party'])\n",
    "\n",
    "# Ensuring the same columns in train and test sets\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Reinitialize and train the RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set and calculate RMSE\n",
    "Y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the root mean squared error\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)  # RMSE is just the square root of MSE\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r_squared = r2_score(Y_test, Y_pred)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate mean absolute percentage error (MAPE) avoiding divisions by zero\n",
    "    and handle cases where actual values are zero by excluding them from the calculation.\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Create a mask for elements where the denominator isn't zero\n",
    "    mask = y_true != 0\n",
    "    if np.any(mask):  # Check if there are any non-zero elements to avoid empty slice\n",
    "        mape = np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]) * 100\n",
    "        return np.mean(mape)\n",
    "    else:\n",
    "        return np.nan  # Return NaN if all y_true values are zero or if no valid values are found\n",
    "    \n",
    "\n",
    "mape = mean_absolute_percentage_error(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 141912451.9420818\n",
      "Root Mean Squared Error: 11912.70128652951\n",
      "Mean Absolute Error: 4802.465833333334\n",
      "Mean Absolute Percentage Error: 1320.85%\n",
      "R-squared: 0.5504480231375696\n"
     ]
    }
   ],
   "source": [
    "vars = ['year', 'county_name', 'party', 'totalvotes', \"AV0AA\", \"A88AA\",\"A88AB\",\"A88AC\",\"A88AD\",\"A88AE\"]\n",
    "\n",
    "X_train = train_data.loc[:, vars]\n",
    "Y_train = train_data.loc[:, 'candidatevotes']\n",
    "X_test = test_data.loc[:, vars]\n",
    "Y_test = test_data.loc[:, 'candidatevotes']\n",
    "\n",
    "# Encode categorical data\n",
    "X_train = pd.get_dummies(X_train, columns=['county_name', 'party'])\n",
    "X_test = pd.get_dummies(X_test, columns=['county_name', 'party'])\n",
    "\n",
    "# Ensuring the same columns in train and test sets\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Reinitialize and train the RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set and calculate RMSE\n",
    "Y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the root mean squared error\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)  # RMSE is just the square root of MSE\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r_squared = r2_score(Y_test, Y_pred)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate mean absolute percentage error (MAPE) avoiding divisions by zero\n",
    "    and handle cases where actual values are zero by excluding them from the calculation.\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Create a mask for elements where the denominator isn't zero\n",
    "    mask = y_true != 0\n",
    "    if np.any(mask):  # Check if there are any non-zero elements to avoid empty slice\n",
    "        mape = np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]) * 100\n",
    "        return np.mean(mape)\n",
    "    else:\n",
    "        return np.nan  # Return NaN if all y_true values are zero or if no valid values are found\n",
    "    \n",
    "\n",
    "mape = mean_absolute_percentage_error(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 145329367.75192273\n",
      "Root Mean Squared Error: 12055.263072696618\n",
      "Mean Absolute Error: 4836.608939393939\n",
      "Mean Absolute Percentage Error: 1319.06%\n",
      "R-squared: 0.5396238760238731\n"
     ]
    }
   ],
   "source": [
    "vars = ['year', 'county_name', 'party', 'totalvotes', \"AV0AA\", \"B69AA\", \"B69AB\", \"B69AC\"]\n",
    "\n",
    "X_train = train_data.loc[:, vars]\n",
    "Y_train = train_data.loc[:, 'candidatevotes']\n",
    "X_test = test_data.loc[:, vars]\n",
    "Y_test = test_data.loc[:, 'candidatevotes']\n",
    "\n",
    "# Encode categorical data\n",
    "X_train = pd.get_dummies(X_train, columns=['county_name', 'party'])\n",
    "X_test = pd.get_dummies(X_test, columns=['county_name', 'party'])\n",
    "\n",
    "# Ensuring the same columns in train and test sets\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Reinitialize and train the RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set and calculate RMSE\n",
    "Y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the root mean squared error\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)  # RMSE is just the square root of MSE\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r_squared = r2_score(Y_test, Y_pred)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate mean absolute percentage error (MAPE) avoiding divisions by zero\n",
    "    and handle cases where actual values are zero by excluding them from the calculation.\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Create a mask for elements where the denominator isn't zero\n",
    "    mask = y_true != 0\n",
    "    if np.any(mask):  # Check if there are any non-zero elements to avoid empty slice\n",
    "        mape = np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]) * 100\n",
    "        return np.mean(mape)\n",
    "    else:\n",
    "        return np.nan  # Return NaN if all y_true values are zero or if no valid values are found\n",
    "    \n",
    "\n",
    "mape = mean_absolute_percentage_error(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both education and income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 175883680.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 70369456.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 52454616.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 46990356.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 27130584.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 17845032.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 10703500.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 11350266.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 18389630.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 16909430.0000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Mean Squared Error: 62246752.5332417\n",
      "Root Mean Squared Error: 7889.66111650188\n",
      "Mean Absolute Error: 2736.6932051976523\n",
      "Mean Absolute Percentage Error: 10284.71%\n",
      "R-squared: 0.8028139865696495\n"
     ]
    }
   ],
   "source": [
    "vars = ['year', 'county_name', 'party', 'totalvotes', \"AV0AA\", \"B69AA\", \"B69AB\", \"B69AC\", \"A88AA\",\"A88AB\",\"A88AC\",\"A88AD\",\"A88AE\"]\n",
    "\n",
    "X_train = train_data.loc[:, vars]\n",
    "Y_train = train_data.loc[:, 'candidatevotes']\n",
    "X_test = test_data.loc[:, vars]\n",
    "Y_test = test_data.loc[:, 'candidatevotes']\n",
    "\n",
    "# Preprocessing\n",
    "categorical_features = ['party', 'county_name']\n",
    "numeric_features = ['year', 'totalvotes', \"AV0AA\", \"B69AA\", \"B69AB\", \"B69AC\", \"A88AA\",\"A88AB\",\"A88AC\",\"A88AD\",\"A88AE\"]\n",
    "\n",
    "# Create a transformer for numerical attributes\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create a transformer for categorical attributes\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine transformers into a preprocessor step\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit the preprocessor on the training data\n",
    "preprocessor.fit(X_train)\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Model creation\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_transformed.shape[1],)),\n",
    "    Dense(112, activation='relu'),\n",
    "    Dense(96, activation='relu'),\n",
    "    Dense(80, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_transformed, Y_train, epochs=10, batch_size=10)\n",
    "\n",
    "# Predict using the model\n",
    "Y_pred = model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)  # RMSE is just the square root of MSE\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "mape = mean_absolute_percentage_error(Y_test, Y_pred)\n",
    "r_squared = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692us/step - loss: 224744784.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 77939032.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 42922700.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 21906416.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 20774394.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 13563498.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 15109191.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 11771179.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 10913584.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 11338197.0000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Mean Squared Error: 65046350.94308153\n",
      "Root Mean Squared Error: 8065.131799486077\n",
      "Mean Absolute Error: 2918.507088169907\n",
      "Mean Absolute Percentage Error: 11138.81%\n",
      "R-squared: 0.7939453849611166\n"
     ]
    }
   ],
   "source": [
    "vars = ['year', 'county_name', 'party', 'totalvotes', \"AV0AA\", \"A88AA\",\"A88AB\",\"A88AC\",\"A88AD\",\"A88AE\"]\n",
    "\n",
    "X_train = train_data.loc[:, vars]\n",
    "Y_train = train_data.loc[:, 'candidatevotes']\n",
    "X_test = test_data.loc[:, vars]\n",
    "Y_test = test_data.loc[:, 'candidatevotes']\n",
    "\n",
    "# Preprocessing\n",
    "categorical_features = ['party', 'county_name']\n",
    "numeric_features = ['year', 'totalvotes',\"AV0AA\", \"A88AA\",\"A88AB\",\"A88AC\",\"A88AD\",\"A88AE\"]\n",
    "\n",
    "# Create a transformer for numerical attributes\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create a transformer for categorical attributes\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine transformers into a preprocessor step\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit the preprocessor on the training data\n",
    "preprocessor.fit(X_train)\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Model creation\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_transformed.shape[1],)),\n",
    "    Dense(112, activation='relu'),\n",
    "    Dense(96, activation='relu'),\n",
    "    Dense(80, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_transformed, Y_train, epochs=10, batch_size=10)\n",
    "\n",
    "# Predict using the model\n",
    "Y_pred = model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)  # RMSE is just the square root of MSE\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "mape = mean_absolute_percentage_error(Y_test, Y_pred)\n",
    "r_squared = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 177662432.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 64038144.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 40389308.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 18724654.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 21435274.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 9249084.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 14202299.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 8590540.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 7997700.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 8560124.0000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Mean Squared Error: 58408381.04854642\n",
      "Root Mean Squared Error: 7642.537605307966\n",
      "Mean Absolute Error: 2583.5330708532624\n",
      "Mean Absolute Percentage Error: 12535.49%\n",
      "R-squared: 0.8149732260533095\n"
     ]
    }
   ],
   "source": [
    "vars = ['year', 'county_name', 'party', 'totalvotes', \"AV0AA\", \"B69AA\", \"B69AB\", \"B69AC\"]\n",
    "\n",
    "X_train = train_data.loc[:, vars]\n",
    "Y_train = train_data.loc[:, 'candidatevotes']\n",
    "X_test = test_data.loc[:, vars]\n",
    "Y_test = test_data.loc[:, 'candidatevotes']\n",
    "\n",
    "# Preprocessing\n",
    "categorical_features = ['party', 'county_name']\n",
    "numeric_features = ['year', 'totalvotes',\"AV0AA\", \"B69AA\", \"B69AB\", \"B69AC\"]\n",
    "\n",
    "# Create a transformer for numerical attributes\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create a transformer for categorical attributes\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine transformers into a preprocessor step\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit the preprocessor on the training data\n",
    "preprocessor.fit(X_train)\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Model creation\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_transformed.shape[1],)),\n",
    "    Dense(112, activation='relu'),\n",
    "    Dense(96, activation='relu'),\n",
    "    Dense(80, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_transformed, Y_train, epochs=10, batch_size=10)\n",
    "\n",
    "# Predict using the model\n",
    "Y_pred = model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)  # RMSE is just the square root of MSE\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "mape = mean_absolute_percentage_error(Y_test, Y_pred)\n",
    "r_squared = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA most significant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 207087632.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 85634808.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 56573880.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 43047792.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 24963896.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - loss: 16389416.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 21042450.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 12497128.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 11640304.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 12575713.0000\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Mean Squared Error: 98903650.07353489\n",
      "Root Mean Squared Error: 9945.031426472964\n",
      "Mean Absolute Error: 3221.053388046496\n",
      "Mean Absolute Percentage Error: 14545.11%\n",
      "R-squared: 0.6866918244241603\n"
     ]
    }
   ],
   "source": [
    "vars = ['year', 'county_name', 'party', 'totalvotes', \"BS4AA\", \"B84AA\", \"BS4AG\", \"C54AD\", \"AB2AA\", \"BD5AA\", \"C54AB\", \"C54AG\", \"B69AA\", \"C54AE\", \"AK7AC\", \"BV8AA\", \"AB9AO\", \"A67AL\"]\n",
    "\n",
    "X_train = train_data.loc[:, vars]\n",
    "Y_train = train_data.loc[:, 'candidatevotes']\n",
    "X_test = test_data.loc[:, vars]\n",
    "Y_test = test_data.loc[:, 'candidatevotes']\n",
    "\n",
    "# Preprocessing\n",
    "categorical_features = ['party', 'county_name']\n",
    "numeric_features = ['year', 'totalvotes',\"BS4AA\", \"B84AA\", \"BS4AG\", \"C54AD\", \"AB2AA\", \"BD5AA\", \"C54AB\", \"C54AG\", \"B69AA\", \"C54AE\", \"AK7AC\", \"BV8AA\", \"AB9AO\", \"A67AL\"]\n",
    "\n",
    "# Create a transformer for numerical attributes\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create a transformer for categorical attributes\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine transformers into a preprocessor step\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit the preprocessor on the training data\n",
    "preprocessor.fit(X_train)\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Model creation\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_transformed.shape[1],)),\n",
    "    Dense(112, activation='relu'),\n",
    "    Dense(96, activation='relu'),\n",
    "    Dense(80, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_transformed, Y_train, epochs=10, batch_size=10)\n",
    "\n",
    "# Predict using the model\n",
    "Y_pred = model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)  # RMSE is just the square root of MSE\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "mape = mean_absolute_percentage_error(Y_test, Y_pred)\n",
    "r_squared = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus in on income data, specifically the variables A88AA-A88AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on relevant columns: income brackets, candidate votes, party, and year\n",
    "election_income_df = pd.read_csv(\"properly_merged_data.csv\")\n",
    "income_columns = ['year', 'county_name', 'party', 'candidatevotes', 'A88AA', 'A88AB', 'A88AC', 'A88AD', 'A88AE']\n",
    "election_income_df = election_income_df[income_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "      <th>candidatevotes</th>\n",
       "      <th>A88AA_votes</th>\n",
       "      <th>A88AB_votes</th>\n",
       "      <th>A88AC_votes</th>\n",
       "      <th>A88AD_votes</th>\n",
       "      <th>A88AE_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>951375</td>\n",
       "      <td>45779.56</td>\n",
       "      <td>36021.81</td>\n",
       "      <td>96500.63</td>\n",
       "      <td>277026.41</td>\n",
       "      <td>496046.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>43915</td>\n",
       "      <td>1855.50</td>\n",
       "      <td>1481.25</td>\n",
       "      <td>4064.90</td>\n",
       "      <td>12164.46</td>\n",
       "      <td>24348.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>21309</td>\n",
       "      <td>1059.07</td>\n",
       "      <td>875.65</td>\n",
       "      <td>2310.07</td>\n",
       "      <td>6457.92</td>\n",
       "      <td>10606.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1190770</td>\n",
       "      <td>50922.74</td>\n",
       "      <td>42192.02</td>\n",
       "      <td>117022.13</td>\n",
       "      <td>349425.43</td>\n",
       "      <td>631207.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1129032</td>\n",
       "      <td>52472.01</td>\n",
       "      <td>41178.60</td>\n",
       "      <td>110850.62</td>\n",
       "      <td>322670.89</td>\n",
       "      <td>601859.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>21748</td>\n",
       "      <td>1007.19</td>\n",
       "      <td>829.46</td>\n",
       "      <td>2257.94</td>\n",
       "      <td>6472.62</td>\n",
       "      <td>11180.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1456202</td>\n",
       "      <td>61165.21</td>\n",
       "      <td>50744.80</td>\n",
       "      <td>141382.62</td>\n",
       "      <td>425091.70</td>\n",
       "      <td>777817.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1537789</td>\n",
       "      <td>54460.42</td>\n",
       "      <td>37820.51</td>\n",
       "      <td>98917.28</td>\n",
       "      <td>302044.10</td>\n",
       "      <td>1044546.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>32338</td>\n",
       "      <td>1161.05</td>\n",
       "      <td>826.43</td>\n",
       "      <td>2224.23</td>\n",
       "      <td>6708.24</td>\n",
       "      <td>21418.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1479795</td>\n",
       "      <td>50155.50</td>\n",
       "      <td>35994.99</td>\n",
       "      <td>96330.24</td>\n",
       "      <td>300864.11</td>\n",
       "      <td>996450.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1543476</td>\n",
       "      <td>53921.53</td>\n",
       "      <td>37230.94</td>\n",
       "      <td>97379.25</td>\n",
       "      <td>299147.46</td>\n",
       "      <td>1055796.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>49958</td>\n",
       "      <td>1740.46</td>\n",
       "      <td>1232.02</td>\n",
       "      <td>3315.05</td>\n",
       "      <td>10146.74</td>\n",
       "      <td>33523.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1570915</td>\n",
       "      <td>52790.00</td>\n",
       "      <td>38078.64</td>\n",
       "      <td>101612.88</td>\n",
       "      <td>317563.89</td>\n",
       "      <td>1060869.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1511667</td>\n",
       "      <td>44360.82</td>\n",
       "      <td>25398.26</td>\n",
       "      <td>70110.89</td>\n",
       "      <td>237588.73</td>\n",
       "      <td>1134208.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>185424</td>\n",
       "      <td>5033.78</td>\n",
       "      <td>2961.07</td>\n",
       "      <td>8154.32</td>\n",
       "      <td>28775.25</td>\n",
       "      <td>140499.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1572721</td>\n",
       "      <td>46878.43</td>\n",
       "      <td>28295.04</td>\n",
       "      <td>78695.05</td>\n",
       "      <td>272837.17</td>\n",
       "      <td>1146015.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1993625</td>\n",
       "      <td>62622.08</td>\n",
       "      <td>35581.03</td>\n",
       "      <td>94734.65</td>\n",
       "      <td>316006.56</td>\n",
       "      <td>1484680.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020</td>\n",
       "      <td>LIBERTARIAN</td>\n",
       "      <td>56747</td>\n",
       "      <td>1694.12</td>\n",
       "      <td>999.86</td>\n",
       "      <td>2668.57</td>\n",
       "      <td>9222.42</td>\n",
       "      <td>42162.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>16956</td>\n",
       "      <td>506.83</td>\n",
       "      <td>291.57</td>\n",
       "      <td>767.28</td>\n",
       "      <td>2601.86</td>\n",
       "      <td>12788.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1794029</td>\n",
       "      <td>54808.56</td>\n",
       "      <td>33163.60</td>\n",
       "      <td>90975.60</td>\n",
       "      <td>313297.66</td>\n",
       "      <td>1301783.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year        party  candidatevotes  A88AA_votes  A88AB_votes  A88AC_votes  \\\n",
       "0   2000     DEMOCRAT          951375     45779.56     36021.81     96500.63   \n",
       "1   2000        GREEN           43915      1855.50      1481.25      4064.90   \n",
       "2   2000        OTHER           21309      1059.07       875.65      2310.07   \n",
       "3   2000   REPUBLICAN         1190770     50922.74     42192.02    117022.13   \n",
       "4   2004     DEMOCRAT         1129032     52472.01     41178.60    110850.62   \n",
       "5   2004        OTHER           21748      1007.19       829.46      2257.94   \n",
       "6   2004   REPUBLICAN         1456202     61165.21     50744.80    141382.62   \n",
       "7   2008     DEMOCRAT         1537789     54460.42     37820.51     98917.28   \n",
       "8   2008        OTHER           32338      1161.05       826.43      2224.23   \n",
       "9   2008   REPUBLICAN         1479795     50155.50     35994.99     96330.24   \n",
       "10  2012     DEMOCRAT         1543476     53921.53     37230.94     97379.25   \n",
       "11  2012        OTHER           49958      1740.46      1232.02      3315.05   \n",
       "12  2012   REPUBLICAN         1570915     52790.00     38078.64    101612.88   \n",
       "13  2016     DEMOCRAT         1511667     44360.82     25398.26     70110.89   \n",
       "14  2016        OTHER          185424      5033.78      2961.07      8154.32   \n",
       "15  2016   REPUBLICAN         1572721     46878.43     28295.04     78695.05   \n",
       "16  2020     DEMOCRAT         1993625     62622.08     35581.03     94734.65   \n",
       "17  2020  LIBERTARIAN           56747      1694.12       999.86      2668.57   \n",
       "18  2020        OTHER           16956       506.83       291.57       767.28   \n",
       "19  2020   REPUBLICAN         1794029     54808.56     33163.60     90975.60   \n",
       "\n",
       "    A88AD_votes  A88AE_votes  \n",
       "0     277026.41    496046.60  \n",
       "1      12164.46     24348.89  \n",
       "2       6457.92     10606.29  \n",
       "3     349425.43    631207.68  \n",
       "4     322670.89    601859.89  \n",
       "5       6472.62     11180.78  \n",
       "6     425091.70    777817.67  \n",
       "7     302044.10   1044546.69  \n",
       "8       6708.24     21418.06  \n",
       "9     300864.11    996450.16  \n",
       "10    299147.46   1055796.82  \n",
       "11     10146.74     33523.73  \n",
       "12    317563.89   1060869.58  \n",
       "13    237588.73   1134208.30  \n",
       "14     28775.25    140499.57  \n",
       "15    272837.17   1146015.32  \n",
       "16    316006.56   1484680.67  \n",
       "17      9222.42     42162.04  \n",
       "18      2601.86     12788.46  \n",
       "19    313297.66   1301783.59  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election_income_df['total_population'] = election_income_df[['A88AA', 'A88AB', 'A88AC', 'A88AD', 'A88AE']].sum(axis=1)\n",
    "\n",
    "# Calculate the proportion of each income bracket\n",
    "for column in ['A88AA', 'A88AB', 'A88AC', 'A88AD', 'A88AE']:\n",
    "    election_income_df[column + '_prop'] = election_income_df[column] / election_income_df['total_population']\n",
    "\n",
    "# Apply the proportions to the candidatevotes to estimate votes per income bracket\n",
    "for column in ['A88AA', 'A88AB', 'A88AC', 'A88AD', 'A88AE']:\n",
    "    election_income_df[column + '_votes'] = election_income_df[column + '_prop'] * election_income_df['candidatevotes']\n",
    "\n",
    "# Now group by year and party and sum the estimated votes for each income bracket\n",
    "aggregated_data = election_income_df.groupby(['year', 'party']).agg({\n",
    "    'candidatevotes': 'sum',\n",
    "    'A88AA_votes': 'sum',\n",
    "    'A88AB_votes': 'sum',\n",
    "    'A88AC_votes': 'sum',\n",
    "    'A88AD_votes': 'sum',\n",
    "    'A88AE_votes': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "aggregated_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
